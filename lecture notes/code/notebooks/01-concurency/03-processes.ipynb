{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7971a7f6",
   "metadata": {},
   "source": [
    "# Multiprocessing: True Parallelism for CPU-Bound Work\n",
    "\n",
    "We’ll compare **sequential** vs **ProcessPoolExecutor** using the same CPU-heavy task.\n",
    "\n",
    "Plan:\n",
    "1) Baseline (serial)\n",
    "2) Parallel with `map()` — ordered, uniform tasks\n",
    "3) Parallel with `submit()` + `as_completed()` — streaming, variable tasks\n",
    "\n",
    "Notes:\n",
    "- These cells are designed to run as **scripts**; in notebooks, multiprocessing can be\n",
    "  finicky. Prefer saving to `.py` and running with `python file.py`.\n",
    "- Always keep functions **module-level** and guard entry with:\n",
    "  `if __name__ == \"__main__\":`\n",
    "- Observe CPU monitors (htop/Activity Monitor): all cores should light up in parallel runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12834e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from mp_tasks import cpu_heavy\n",
    "\n",
    "rng = random.Random(0)\n",
    "\n",
    "n_workers = os.cpu_count() or 4\n",
    "\n",
    "uniform_tasks = [12_000_000] * n_workers\n",
    "nonuniform_tasks = [8_000_000 + rng.randint(0, 8_000_000) for _ in range(n_workers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54630949",
   "metadata": {},
   "source": [
    "### Baseline — Sequential CPU-Bound Execution\n",
    "\n",
    "Purpose:\n",
    "- Establish the runtime when running the CPU-heavy function **back-to-back** on one core.\n",
    "- This is our **reference** for speedup.\n",
    "\n",
    "Expect:\n",
    "- One core near 100%.\n",
    "- Total time ≈ repeats × single-task time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial: ran 12 CPU tasks in 12.61s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "for t in uniform_tasks:\n",
    "    cpu_heavy(t)\n",
    "\n",
    "dt = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Serial: ran {len(uniform_tasks)} CPU tasks in {dt:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291472f7",
   "metadata": {},
   "source": [
    "### Parallel — `ProcessPoolExecutor.map()` (ordered, uniform tasks)\n",
    "\n",
    "Purpose:\n",
    "- Run **one task per core** with identical workloads using `map()`.\n",
    "\n",
    "Key points:\n",
    "- **Ordered results** (same order as inputs).\n",
    "- Great for **uniform durations**.\n",
    "- Consider `chunksize` if tasks are very small.\n",
    "\n",
    "Expect:\n",
    "- All cores active.\n",
    "- Wall time drops by ~number of workers (minus overhead).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c676ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map(): ran 12 CPU tasks in 3.05s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "with ProcessPoolExecutor() as ex:\n",
    "    results = list(ex.map(cpu_heavy, uniform_tasks, chunksize=1))\n",
    "\n",
    "dt = time.perf_counter() - t0\n",
    "\n",
    "print(f\"map(): ran {len(uniform_tasks)} CPU tasks in {dt:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949f13a",
   "metadata": {},
   "source": [
    "### Parallel — `submit()` + `as_completed()` (streaming, variable tasks)\n",
    "\n",
    "Purpose:\n",
    "- Schedule tasks individually and **consume results as they finish**.\n",
    "\n",
    "Key points:\n",
    "- **Out-of-order** completion reflects true variability in work.\n",
    "- Ideal for progress reporting and early aggregation.\n",
    "- Handle exceptions via `f.result()` (they propagate from workers).\n",
    "\n",
    "Expect:\n",
    "- Intermittent progress prints as tasks complete.\n",
    "- Similar total speedup to `map()`, but more responsive output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635194e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/12 finished...\n",
      "6/12 finished...\n",
      "9/12 finished...\n",
      "12/12 finished...\n",
      "submit()+as_completed(): ran 12 CPU tasks in 3.18s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "    \n",
    "with ProcessPoolExecutor() as ex:\n",
    "    futures = [ex.submit(cpu_heavy, n) for n in nonuniform_tasks]\n",
    "    done = 0\n",
    "    \n",
    "    for f in as_completed(futures):\n",
    "        _ = f.result()  # raises if worker failed\n",
    "        done += 1\n",
    "        if done % 3 == 0:\n",
    "            print(f\"{done}/{len(nonuniform_tasks)} finished...\")\n",
    "\n",
    "dt = time.perf_counter() - t0\n",
    "\n",
    "print(f\"submit() + as_completed(): ran {len(nonuniform_tasks)} CPU tasks in {dt:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
